{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_dataset():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "    x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "    \n",
    "    y_train = y_train.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "    \n",
    "    x_val = x_train[-10000:]\n",
    "    y_val = y_train[-10000:]\n",
    "    x_train = x_train[:-10000]\n",
    "    y_train = y_train[:-10000]\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = get_mnist_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_mlp():\n",
    "    tf.random.set_seed(42)  # set random seed\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(784,), name='digits')\n",
    "    x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
    "    x = layers.Dense(32, activation='relu', name='dense_2')(x)\n",
    "    outputs = layers.Dense(10, activation='softmax', name='predictions')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_compiler(\n",
    "    model,\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['sparse_categorical_accuracy']):\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = get_simple_mlp()\n",
    "model_1 = model_compiler(model_1)\n",
    "\n",
    "model_2 = get_simple_mlp()\n",
    "model_2 = model_compiler(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 3s 64us/sample - loss: 1.7218 - sparse_categorical_accuracy: 0.7545\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 3s 69us/sample - loss: 1.6188 - sparse_categorical_accuracy: 0.8467\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 5s 105us/sample - loss: 1.6047 - sparse_categorical_accuracy: 0.8584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1400cd3d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 1.7218 - sparse_categorical_accuracy: 0.7545\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 3s 66us/sample - loss: 1.6188 - sparse_categorical_accuracy: 0.8467\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 1.6047 - sparse_categorical_accuracy: 0.8584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14be7c050>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_determinism(model_1, model_2):\n",
    "    \n",
    "    print('Check trainable weights')  # check trainable weights\n",
    "    weights_1 = model_1.trainable_weights\n",
    "    weights_2 = model_2.trainable_weights\n",
    "    for w1, w2 in zip(weights_1, weights_2):\n",
    "        w1 = w1.numpy().flatten()\n",
    "        w2 = w2.numpy().flatten()\n",
    "        print('num params: ', len(w1))\n",
    "        np.testing.assert_allclose(w1, w2, rtol=1e-6, atol=1e-6)\n",
    "        \n",
    "    print('\\nCheck validation scores')  # check validation socres\n",
    "    val_1 = model_1.evaluate(x_val, y_val, batch_size=64, verbose=3)\n",
    "    val_2 = model_2.evaluate(x_val, y_val, batch_size=64, verbose=3)\n",
    "    print('model_1 - loss: {:.8f}, metric: {}'.format(val_1[0], val_1[1:]))\n",
    "    print('model_2 - loss: {:.8f}, metric: {}'.format(val_2[0], val_2[1:]))\n",
    "    \n",
    "    print('\\nCheck test predictions')  # check test predictions\n",
    "    pred_1 = model_1.predict(x_test)\n",
    "    pred_2 = model_2.predict(x_test)\n",
    "    print('num preds: ', len(pred_1))\n",
    "    np.testing.assert_allclose(pred_1, pred_2, rtol=1e-6, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check trainable weights\n",
      "num params:  50176\n",
      "num params:  64\n",
      "num params:  2048\n",
      "num params:  32\n",
      "num params:  320\n",
      "num params:  10\n",
      "\n",
      "Check validation scores\n",
      "model_1 - loss: 1.59803915, metric: [0.8634]\n",
      "model_2 - loss: 1.59803915, metric: [0.8634]\n",
      "\n",
      "Check test predictions\n",
      "num preds:  10000\n"
     ]
    }
   ],
   "source": [
    "check_determinism(model_1, model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "#         tf.random.set_seed(42)\n",
    "        super(MLP, self).__init__()\n",
    "        self.dense_1 = layers.Dense(64, activation='relu', name='dense_1')\n",
    "        self.dense_2 = layers.Dense(32, activation='relu', name='dense_2')\n",
    "        self.classifier = layers.Dense(10, activation='softmax', name='predictions')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "#         tf.random.set_seed(42)\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.dense_2(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(42)\n",
    "mlp_1 = MLP()\n",
    "# tf.random.set_seed(42)\n",
    "mlp_2 = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(42)\n",
    "mlp_1 = model_compiler(mlp_1)\n",
    "# tf.random.set_seed(42)\n",
    "mlp_2 = model_compiler(mlp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 3s 61us/sample - loss: 1.7218 - sparse_categorical_accuracy: 0.7545\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 2s 49us/sample - loss: 1.6188 - sparse_categorical_accuracy: 0.8467\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 2s 50us/sample - loss: 1.6047 - sparse_categorical_accuracy: 0.85840s - loss: 1.6051 - sparse_categorical_accuracy: 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x150436290>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "mlp_1.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 4s 75us/sample - loss: 1.7218 - sparse_categorical_accuracy: 0.7545\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 2s 47us/sample - loss: 1.6188 - sparse_categorical_accuracy: 0.8467\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 3s 53us/sample - loss: 1.6047 - sparse_categorical_accuracy: 0.8584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14fad27d0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "mlp_2.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check trainable weights\n",
      "num params:  50176\n",
      "num params:  64\n",
      "num params:  2048\n",
      "num params:  32\n",
      "num params:  320\n",
      "num params:  10\n",
      "\n",
      "Check validation scores\n",
      "model_1 - loss: 1.59803915, metric: [0.8634]\n",
      "model_2 - loss: 1.59803915, metric: [0.8634]\n",
      "\n",
      "Check test predictions\n",
      "num preds:  10000\n"
     ]
    }
   ],
   "source": [
    "check_determinism(mlp_1, mlp_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when only `set random seed` before `fit` call, determinism works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
