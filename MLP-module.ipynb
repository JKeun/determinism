{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from src.DataSource import DataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./data/titanic_train.csv\"\n",
    "ds = DataSource(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.data_load_split(target=['Survived'],\n",
    "                   ignore=['Name', 'Cabin', 'Ticket'])\n",
    "ds.define_problem()\n",
    "ds.train_val_split(ratio=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Binary'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.data_preprocess(ds.X_train, ds.y_train, train_set=True)\n",
    "ds.data_preprocess(ds.X_val, ds.y_val, train_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_mlp(X, y, problem, hidden_layers=1, unit=16):\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    structure_info = {'hidden_layers': hidden_layers,\n",
    "                      'units': unit}\n",
    "    \n",
    "    tf.keras.backend.clear_session()  # clear graph session\n",
    "    model = keras.Sequential()\n",
    "    # input layer\n",
    "    model.add(keras.layers.Input(shape=(X.shape[1],)))\n",
    "    # hidden layer\n",
    "    for _ in range(hidden_layers):\n",
    "#         tf.random.set_seed(42)\n",
    "        model.add(keras.layers.Dense(unit, activation='relu'))\n",
    "    # output layer\n",
    "    if problem == \"Regression\":\n",
    "        model.add(keras.layers.Dense(1))\n",
    "    elif problem == \"Binary\":\n",
    "        model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    else:\n",
    "        model.add(keras.layers.Dense(y.shape[1], activation='softmax'))\n",
    "    \n",
    "    return model, structure_info\n",
    "\n",
    "\n",
    "def get_mlps(X, y, problem, max_hidden_layers=1, units=[16], use_all=False):\n",
    "    if use_all:\n",
    "        max_hidden_layers = 3\n",
    "        units = [16, 32, 64, 128, 256]\n",
    "    else:\n",
    "        max_hidden_layers = max_hidden_layers\n",
    "        units = units\n",
    "        \n",
    "    structure_grid = [np.arange(max_hidden_layers)+1, units]\n",
    "    structured_models = []\n",
    "    structures_info = []\n",
    "    for param_tuple in itertools.product(*structure_grid):\n",
    "        model, structure_info = get_single_mlp(X, y, problem,\n",
    "                                               hidden_layers=param_tuple[0],\n",
    "                                               unit=param_tuple[1])\n",
    "        structured_models.append(model)\n",
    "        structures_info.append(structure_info)\n",
    "        \n",
    "    return structured_models, structures_info\n",
    "\n",
    "\n",
    "def compile_model(problem, structured_model, optimizer='adam', lr=0.01):\n",
    "    # automatically set loss and metrics according to problem\n",
    "    if problem == \"Regression\":\n",
    "        loss = keras.losses.MSE\n",
    "        metrics = ['MSE', 'MAE']\n",
    "    elif problem == \"Binary\":\n",
    "        loss = keras.losses.binary_crossentropy\n",
    "        metrics = ['accuracy']\n",
    "    else:\n",
    "        loss = keras.losses.categorical_crossentropy\n",
    "        metrics = ['accuracy']\n",
    "    \n",
    "    # match optimizer argument to optimizer Class\n",
    "    optimizer_classes = {'adadelta': keras.optimizers.Adadelta, 'sgd': keras.optimizers.SGD,\n",
    "                         'adam': keras.optimizers.Adam, 'adagrad': keras.optimizers.Adagrad,\n",
    "                         'adamax': keras.optimizers.Adamax, 'rmsprop': keras.optimizers.RMSprop}\n",
    "    optimizer_class = optimizer_classes[optimizer]\n",
    "    \n",
    "    optimizer_info = {'optimizer': optimizer,\n",
    "                      'lr': lr}\n",
    "    \n",
    "    # compile model\n",
    "    compiled_model = keras.models.clone_model(structured_model)  # avoid overriding model when compile_models\n",
    "    compiled_model.compile(optimizer=optimizer_class(lr),\n",
    "                           loss=loss,\n",
    "                           metrics=metrics)\n",
    "    \n",
    "    return compiled_model, optimizer_info\n",
    "\n",
    "\n",
    "def compile_models(problem, structured_models, structures_info, optimizers=['adam'], lrs=[0.01], use_all=False):\n",
    "    if use_all:\n",
    "        optimizers = ['adadelta', 'sgd', 'adam', 'adagrad', 'adamax', 'rmsprop']\n",
    "        lrs = [0.001, 0.01, 0.02, 0.1]\n",
    "    else:\n",
    "        optimizers = optimizers\n",
    "        lrs = lrs\n",
    "    \n",
    "    compiled_models = []\n",
    "    compiled_models_info = []\n",
    "    compile_grid = [zip(structured_models, structures_info), optimizers, lrs]\n",
    "    for compile_tuple in itertools.product(*compile_grid):\n",
    "        model = compile_tuple[0][0]\n",
    "        model_info = compile_tuple[0][1]\n",
    "        optimizer = compile_tuple[1]\n",
    "        lr = compile_tuple[2]\n",
    "        \n",
    "        model, optimizer_info = compile_model(problem, model,\n",
    "                                              optimizer=optimizer, lr=lr)\n",
    "        compiled_models.append(model)\n",
    "        compiled_models_info.append({\"structure\": model_info,\n",
    "                                     \"optimizer\": optimizer_info})\n",
    "        \n",
    "    return compiled_models, compiled_models_info\n",
    "\n",
    "\n",
    "def train_model(compiled_model, X_train, y_train, X_val=None, y_val=None,\n",
    "                batch_size=None, epochs=1, verbose=0, callbacks=None,\n",
    "                shuffle=True, steps_per_epoch=None):\n",
    "    if callbacks:\n",
    "        callbacks = callbacks\n",
    "    else:\n",
    "        callbacks = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  patience=5,\n",
    "                                                  restore_best_weights=True)\n",
    "    compiled_model.fit(x=X_train, y=y_train,\n",
    "                       batch_size=batch_size, epochs=epochs,\n",
    "                       verbose=verbose, callbacks=callbacks,\n",
    "                       validation_data=(X_val, y_val), shuffle=shuffle)\n",
    "    val_loss = compiled_model.evaluate(X_val, y_val, verbose=verbose)\n",
    "    print(\"{} model is trained. best val loss is: {}\".format(compiled_model.name, val_loss))\n",
    "    \n",
    "    return compiled_model, val_loss\n",
    "\n",
    "\n",
    "def train_models(compiled_models, X_train, y_train, X_val=None, y_val=None,\n",
    "                 batch_size=None, epochs=1, verbose=0, callbacks=None,\n",
    "                 shuffle=True, steps_per_epoch=None):\n",
    "    trained_models = []\n",
    "    val_losses = []\n",
    "    for compiled_model in compiled_models:\n",
    "        trained_model, val_loss = train_model(compiled_model,\n",
    "                                              X_train, y_train,\n",
    "                                              X_val=X_val, y_val=y_val,\n",
    "                                              batch_size=batch_size, epochs=epochs,\n",
    "                                              verbose=verbose, callbacks=callbacks,\n",
    "                                              shuffle=shuffle, steps_per_epoch=steps_per_epoch)\n",
    "        trained_models.append(trained_model)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "    return trained_models, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1, model_info = get_single_mlp(ds.trans_X_train, ds.trans_y_train, ds.problem, hidden_layers=1, unit=16)\n",
    "model2, model_info = get_single_mlp(ds.trans_X_train, ds.trans_y_train, ds.problem, hidden_layers=2, unit=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, models_info = get_mlps(ds.trans_X_train, ds.trans_y_train, ds.problem,\n",
    "                               max_hidden_layers=2, units=[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.7238\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.7095\n"
     ]
    }
   ],
   "source": [
    "models_1 = [model1, model2]\n",
    "for model in models_1:\n",
    "    model.compile(optimizer=keras.optimizers.Adadelta(0.1),\n",
    "              loss=keras.losses.binary_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "# for model in models_1:\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    model.fit(x=ds.trans_X_train, y=ds.trans_y_train,\n",
    "          batch_size=64, epochs=10,\n",
    "          verbose=0, callbacks=[callbacks],\n",
    "          validation_data=(ds.trans_X_val, ds.trans_y_val), shuffle=True)\n",
    "    \n",
    "# for model in models_1:\n",
    "    model.evaluate(ds.trans_X_val, ds.trans_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.7238\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.7095\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model.compile(optimizer=keras.optimizers.Adadelta(0.1),\n",
    "              loss=keras.losses.binary_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# for model in models:\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    model.fit(x=ds.trans_X_train, y=ds.trans_y_train,\n",
    "          batch_size=64, epochs=10,\n",
    "          verbose=0, callbacks=[callbacks],\n",
    "          validation_data=(ds.trans_X_val, ds.trans_y_val), shuffle=True)\n",
    "\n",
    "# for model in models:\n",
    "    model.evaluate(ds.trans_X_val, ds.trans_y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with self code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1, model_info = get_single_mlp(ds.trans_X_train, ds.trans_y_train, ds.problem, hidden_layers=1, unit=16)\n",
    "model2, model_info = get_single_mlp(ds.trans_X_train, ds.trans_y_train, ds.problem, hidden_layers=2, unit=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, models_info = get_mlps(ds.trans_X_train, ds.trans_y_train, ds.problem,\n",
    "                               max_hidden_layers=2, units=[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential model is trained. best val loss is: [0.6487677699043637, 0.680952380952381]\n",
      "sequential model is trained. best val loss is: [0.6704074865295774, 0.6142857142857143]\n"
     ]
    }
   ],
   "source": [
    "models_1 = [model1, model2]\n",
    "for model in models_1:\n",
    "    model, _ = compile_model(ds.problem, model, optimizer='adadelta', lr=0.1)\n",
    "    \n",
    "    model, _ = train_model(model, ds.trans_X_train, ds.trans_y_train,\n",
    "                            ds.trans_X_val, ds.trans_y_val, batch_size=64, epochs=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential model is trained. best val loss is: [0.6629807767413911, 0.6428571428571429]\n",
      "sequential model is trained. best val loss is: [0.6637158388183231, 0.7523809523809524]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model, _ = compile_model(ds.problem, model, optimizer='adadelta', lr=0.1)\n",
    "    \n",
    "    model, _ = train_model(model, ds.trans_X_train, ds.trans_y_train,\n",
    "                            ds.trans_X_val, ds.trans_y_val, batch_size=64, epochs=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.engine.sequential.Sequential at 0x7fe4972dbf98>,\n",
       " {'optimizer': 'adadelta', 'lr': 0.1})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1, _ = compile_model(ds.problem, model1, optimizer='adadelta', lr=0.1)\n",
    "model2, _ = compile_model(ds.problem, model2, optimizer='adadelta', lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential model is trained. best val loss is: [0.6487677699043637, 0.680952380952381]\n",
      "sequential model is trained. best val loss is: [0.6704074865295774, 0.6142857142857143]\n"
     ]
    }
   ],
   "source": [
    "trained_model1, _ = train_model(compiled_model1, ds.trans_X_train, ds.trans_y_train,\n",
    "                            ds.trans_X_val, ds.trans_y_val, batch_size=64, epochs=10)\n",
    "trained_model2, _ = train_model(compiled_model2, ds.trans_X_train, ds.trans_y_train,\n",
    "                            ds.trans_X_val, ds.trans_y_val, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta at 0x7fe500e80780>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model1.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Adadelta/learning_rate:0' shape=() dtype=float32, numpy=0.1>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model1.optimizer.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_1_1/bias:0' shape=(1,) dtype=float64, numpy=array([-0.01316631])>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model1.weights[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential model is trained. best val loss is: [0.6356775516555423, 0.7428571428571429]\n",
      "sequential model is trained. best val loss is: [0.6269156666029068, 0.7380952380952381]\n"
     ]
    }
   ],
   "source": [
    "for model in models_1:\n",
    "    compile_model(ds.problem, model, optimizer='adadelta', lr=0.1)\n",
    "    train_model(model, ds.trans_X_train, ds.trans_y_train,\n",
    "                            ds.trans_X_val, ds.trans_y_val, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<tensorflow.python.keras.engine.sequential.Sequential at 0x7fe4bce35240>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7fe4bcd4d898>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7fe4bcdd32b0>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7fe4bcd62ac8>],\n",
       " [{'hidden_layers': 1, 'units': 16},\n",
       "  {'hidden_layers': 1, 'units': 32},\n",
       "  {'hidden_layers': 2, 'units': 16},\n",
       "  {'hidden_layers': 2, 'units': 32}])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models, models_info = get_mlps(ds.trans_X_train, ds.trans_y_train, ds.problem,\n",
    "                               max_hidden_layers=2, units=[16, 32])\n",
    "models, models_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'structure': {'hidden_layers': 1, 'units': 16},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.1}},\n",
       " {'structure': {'hidden_layers': 1, 'units': 16},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.2}},\n",
       " {'structure': {'hidden_layers': 1, 'units': 16},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.1}},\n",
       " {'structure': {'hidden_layers': 1, 'units': 16},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.2}},\n",
       " {'structure': {'hidden_layers': 1, 'units': 32},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.1}},\n",
       " {'structure': {'hidden_layers': 1, 'units': 32},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.2}},\n",
       " {'structure': {'hidden_layers': 1, 'units': 32},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.1}},\n",
       " {'structure': {'hidden_layers': 1, 'units': 32},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.2}},\n",
       " {'structure': {'hidden_layers': 2, 'units': 16},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.1}},\n",
       " {'structure': {'hidden_layers': 2, 'units': 16},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.2}},\n",
       " {'structure': {'hidden_layers': 2, 'units': 16},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.1}},\n",
       " {'structure': {'hidden_layers': 2, 'units': 16},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.2}},\n",
       " {'structure': {'hidden_layers': 2, 'units': 32},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.1}},\n",
       " {'structure': {'hidden_layers': 2, 'units': 32},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.2}},\n",
       " {'structure': {'hidden_layers': 2, 'units': 32},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.1}},\n",
       " {'structure': {'hidden_layers': 2, 'units': 32},\n",
       "  'optimizer': {'optimizer': 'adam', 'lr': 0.2}}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_models, compiled_models_info = compile_models(ds.problem, models, models_info,\n",
    "                                                       optimizers=['adam', 'adam'],\n",
    "                                                       lrs=[0.1, 0.2])\n",
    "compiled_models_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in compiled_models:\n",
    "#     print(model.optimizer)\n",
    "#     print(model.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential model is trained. best val loss is: [0.423308185168675, 0.8238095238095238]\n"
     ]
    }
   ],
   "source": [
    "trained_model, val_loss = train_model(compiled_model, ds.trans_X_train, ds.trans_y_train,\n",
    "                            ds.trans_X_val, ds.trans_y_val, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.engine.sequential.Sequential at 0x7fe4bcdcfda0>,\n",
       " [0.423308185168675, 0.8238095238095238])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential model is trained. best val loss is: [0.423308185168675, 0.8238095238095238]\n",
      "sequential model is trained. best val loss is: [0.4525207661447071, 0.8333333333333334]\n",
      "sequential model is trained. best val loss is: [0.4323851846513294, 0.7952380952380952]\n",
      "sequential model is trained. best val loss is: [0.5033811021418798, 0.8238095238095238]\n",
      "sequential model is trained. best val loss is: [0.44564959719067526, 0.7952380952380952]\n",
      "sequential model is trained. best val loss is: [0.5284496937479292, 0.7857142857142857]\n",
      "sequential model is trained. best val loss is: [0.45328284388496765, 0.8095238095238095]\n",
      "sequential model is trained. best val loss is: [0.5562368279411679, 0.8142857142857143]\n",
      "sequential model is trained. best val loss is: [0.5119102006866818, 0.8476190476190476]\n",
      "sequential model is trained. best val loss is: [0.5166502918515886, 0.8142857142857143]\n",
      "sequential model is trained. best val loss is: [0.5570542812347412, 0.7952380952380952]\n",
      "sequential model is trained. best val loss is: [0.5622142150288536, 0.8285714285714286]\n",
      "sequential model is trained. best val loss is: [0.48300531847136363, 0.8047619047619048]\n",
      "sequential model is trained. best val loss is: [0.5568731813203721, 0.7857142857142857]\n",
      "sequential model is trained. best val loss is: [0.5453701206615993, 0.8285714285714286]\n",
      "sequential model is trained. best val loss is: [0.5726449415797279, 0.7619047619047619]\n"
     ]
    }
   ],
   "source": [
    "trained_models, val_losses = train_models(compiled_models, ds.trans_X_train, ds.trans_y_train,\n",
    "                            ds.trans_X_val, ds.trans_y_val, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6487677699043637, 0.680952380952381],\n",
       " [0.6321581142289298, 0.7476190476190476],\n",
       " [0.44149042339552014, 0.7904761904761904],\n",
       " [0.47842450312205725, 0.7857142857142857],\n",
       " [0.6223019951865787, 0.7238095238095238],\n",
       " [0.6013998832021441, 0.7666666666666667],\n",
       " [0.47113809017908004, 0.7714285714285715],\n",
       " [0.5103121842656817, 0.8047619047619048],\n",
       " [0.660325829188029, 0.6761904761904762],\n",
       " [0.6169747193654378, 0.7571428571428571],\n",
       " [0.4495628365448543, 0.8095238095238095],\n",
       " [0.5072513847124009, 0.819047619047619],\n",
       " [0.6146161232675825, 0.7619047619047619],\n",
       " [0.5705262615567162, 0.780952380952381],\n",
       " [0.5405400565692356, 0.8142857142857143],\n",
       " [0.49578750616028194, 0.7523809523809524]]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
